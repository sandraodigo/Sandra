---
title: "Sony(SNE) Stock Price Prediction"
author: "Sandra Odigo"
date: "7/31/2020"
output: html_document
---

## Load Required Libraries 
```{r setup, include=FALSE}
#install.packages("timeSeries")
#install.packages("forcast")
#install.packages("tseries")
#install.packages("xts")
#install.packages("MASS")
library(timeSeries)
library(forecast)
library(tseries)
library(xts)
library(MASS)
library(quantmod)
```



##Pull data from Yahoo Finance SNE 
```{r}
getSymbols('SNE', from= '2015-01-01', to='2020-07-24', getSymbols.warning4.0=FALSE)
class(SNE)
```
# The class fucton will tell you what kind of data we're working with. xts simple means we're working with xts object. This means you have the data columes and an index feild with dates in it, which is a little bit different from data that you normally work with in a data frame.


#The pulled data has open_price, high_price, low_price, close, and volume. We are interested in the close_Price to make our predictions, so we put that into a new data frame  
```{r }
SNE_Close_df <- SNE[,4]
```


#We want to check for null values 
```{r}
is.null(SNE_Close_df)
sum(is.na((SNE_Close_df$SNE.Close)))
```

```{r}
plot(SNE_Close_df)
par(mfrow=c(1,2))
```

# Split the data into Test and Train 
```{r}
SplitIndex <- sample(nrow(SNE_Close_df), size=(.7*nrow(SNE_Close_df)), replace=F)
Train <- SNE_Close_df[SplitIndex,]
Test <- SNE_Close_df[-SplitIndex,]
```
# The training data is the the data set we're actually going to use in bulding the ARIMA model, while we use the 30% test data to compare with the forcast generated by the ARIMA model.



#Look at the ACF and PACF to find identifiable lags 
```{r}
acf(Train, main='ACF')
pacf(Train, main='Partial ACF')
```
#The first corresponding value on in the PACF lag is 1, which translates into a p value of 1. this means our data is stationary, it has a constant mean, constant variance, constant autocorrelation. 

#Test findings on original xts object
```{r}
print(adf.test(Train))
auto.arima(SNE_Close_df, seasonal = FALSE) #ARIMA is 0,1,1 is what it recommends 

Fit1<- auto.arima(Train, seasonal = FALSE)
tsdisplay(residuals(Fit1), lag.max = 40, main = '(1,1,0) Model Residual')
auto.arima(SNE_Close_df, seasonal = FALSE)
```
#since the P-value is too high, we will have a couple of fit values that we're going to test their accuracy for a forcasting

```{r}
Fit2<-  arima(Train, order= c(1,2,1)) #custom ARIMA
tsdisplay(residuals(Fit1), lag.max = 40, main = '(1,2,4) Model Residual')
```


```{r}
Fit3<-arima(Train, order= c(3,1,1)) #custom ARIMA
tsdisplay(residuals(Fit1), lag.max = 40, main = '(2,1,4) Model Residual')
```

```{r}
Fit4<- arima(Train, order= c(1,1,1)) #custom ARIMA
tsdisplay(residuals(Fit1), lag.max = 40, main = '(1,1,1) Model Residual')
```

#Plot ARIMA models 
```{r}
par(mfrow=c(2,2))
forcast_period<- 100
#Plot AUTO ARIMA 
forcast1<- forecast(Fit1, h=forcast_period) 
plot(forcast1)
#Plot custome ARIMA 
forcast2<- forecast(Fit2, h=forcast_period)
plot(forcast2)
forcast3<- forecast(Fit3, h=forcast_period)
plot(forcast3)
forcast4<- forecast(Fit4, h=forcast_period)
plot(forcast4)


```

#MAPE accuracy subtract from 100
```{r}
accuracy(forcast1) #98.35%
accuracy(forcast2) #98.35%
accuracy(forcast3) #98.36%
accuracy(forcast4) #98.35%
```
 

#ljung-Box
```{r}
Box.test(Fit4$residuals, lag=5, type = "Ljung-Box")
Box.test(Fit4$residuals, lag=10, type = "Ljung-Box")
Box.test(Fit4$residuals, lag=15, type = "Ljung-Box")
```

 